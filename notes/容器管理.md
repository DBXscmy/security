# 容器与管理

> 这是一篇笔记，内容来源：https://www.kubernetes.org.cn/docs 和 http://docs.kubernetes.org.cn/
>

## kubernetes概述

Kubernetes是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。

Kubernetes一个核心的特点就是能够自主的管理容器来保证云平台中的容器按照用户的期望状态运行着（比如用户想让apache一直运行，用户不需要关心怎么去做，Kubernetes会自动去监控，然后去重启，新建，总之，让apache一直提供服务），管理员可以加载一个微型服务，让规划器来找到合适的位置，同时，Kubernetes也系统提升工具以及人性化方面，让用户能够方便的部署自己的应用（就像canary deployments）。

在Kubenetes中，所有的容器均在Pod中运行,一个Pod可以承载一个或者多个相关的容器，在后边的案例中，同一个Pod中的容器会部署在同一个物理机器上并且能够共享资源。一个Pod也可以包含O个或者多个磁盘卷组（volumes）,这些卷组将会以目录的形式提供给一个容器，或者被所有Pod中的容器共享，对于用户创建的每个Pod,系统会自动选择那个健康并且有足够容量的机器，然后创建类似容器的容器,当容器创建失败的时候，容器会被node agent自动的重启,这个node agent叫kubelet,但是，如果是Pod失败或者机器，它不会自动的转移并且启动，除非用户定义了 replication controller。

用户可以自己创建并管理Pod,Kubernetes将这些操作简化为两个操作：基于相同的Pod配置文件部署多个Pod复制品；创建可替代的Pod当一个Pod挂了或者机器挂了的时候。而Kubernetes API中负责来重新启动，迁移等行为的部分叫做“replication controller”，它根据一个模板生成了一个Pod,然后系统就根据用户的需求创建了许多冗余，这些冗余的Pod组成了一个整个应用，或者服务，或者服务中的一层。一旦一个Pod被创建，系统就会不停的监控Pod的健康情况以及Pod所在主机的健康情况，如果这个Pod因为软件原因挂掉了或者所在的机器挂掉了，replication controller 会自动在一个健康的机器上创建一个一摸一样的Pod,来维持原来的Pod冗余状态不变，一个应用的多个Pod可以共享一个机器。

## Kubernetes设计架构

Kubernetes集群包含有节点代理kubelet和Master组件(APIs, scheduler, etc)，一切都基于分布式的存储系统。下面这张图是Kubernetes的架构图。

![k8s架构图](images/201906/ksarchitecture.png)

### Kubernetes节点

上图中，把服务分为了运行在工作节点上的服务和组成集群级别控制板的服务。

kubernets节点有运行应用容器必备的服务，而这些都是受Master的控制。

每个节点上都要运行docker，docker来负责所有具体的映像下载和容器运行。

Kubernetes主要由以下几个核心组件组成：

- etcd 保存了整个集群的状态；
- apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制。
- controller manager负责维护集群状态，比如故障检修、自动扩展、滚动更新等；
- scheduler 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；
- kubelet 负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；kubelet负责管理pods和它们上面的容器，images镜像、volumes、etc。
- Container runtime 负责镜像管理以及 Pod和容器的真正运行（CRI）
- kube-proxy 负责为Service提供cluster内部的服务发现和负载均衡。每一个节点也运行一个简单的网络代理和负载均衡（详见services FAQ )（PS:官方 英文）。 正如Kubernetes API里面定义的这些服务（详见the services doc）（PS:官方 英文）也可以在各种终端中以轮询的方式做一些简单的TCP和UDP传输。
服务端点目前是通过DNS或者环境变量( Docker-links-compatible 和 Kubernetes{FOO}_SERVICE_HOST 及 {FOO}_SERVICE_PORT 变量都支持)。这些变量由服务代理所管理的端口来解析。

除了核心组件，还有一些推荐的Add-ons：

- kube-dns 负责为整个集群提供DNS服务
- ingress controller为服务提供外网入口
- heapster提供资源监控
- dashboard 提供gui
- federation 提供跨可用区的集群
- fluentd-elasticsearch 提供集群日志采集、存储与查询

![kubernets分层架构](images/201906/kubernets分层架构.jpg)

- 核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境
- 应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等）
- 管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等）
- 接口层：kubectl命令行工具、客户端SDK以及集群联邦
- 生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴
- Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等
- Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等


## 使用kubernetes部署集群

### 基于Docker本地运行Kubernetes

下面的指引将高速你如何通过Docker创建一个单机、单节点的Kubernetes集群。

下图是最终的结果：

![基于docker的单机单节点kubernetes集群](images/201906/基于docker的单机单节点kubernetes集群.jpg)

#### 先决条件

1. 你必须拥有一台安装有Docker的机器。

2. 你的内核必须支持 memory and swap accounting 。确认你的linux内核开启了如下配置：
```
CONFIG_RESOURCE_COUNTERS=y
CONFIG_MEMCG=y
CONFIG_MEMCG_SWAP=y
CONFIG_MEMCG_SWAP_ENABLED=y
CONFIG_MEMCG_KMEM=y

```
查看命令：
```
cat /boot/config-***-generic
```
3. 以命令行参数方式，在内核启动时开启 memory and swap accounting 选项：
```
GRUB_CMDLINE_LINUX="cgroup_enable=memory swapaccount=1"
```
注意：以上只适用于GRUB2。通过查看/proc/cmdline可以确认命令行参数是否已经成功

传给内核：
```
$cat /proc/cmdline
BOOT_IMAGE=/boot/vmlinuz-3.18.4-aufs root=/dev/sda5 ro cgroup_enable=memory
swapaccount=1
```
第一步：运行Etcd
```
docker run --net=host -d gcr.io/google_containers/etcd:2.0.12 /usr/local/bin/etcd --addr=127.0.0.1:4001 --bind-addr=0.0.0.0:4001 --data-dir=/var/etcd/data
```
第二步：启动master
```
docker run \
    --volume=/:/rootfs:ro \
    --volume=/sys:/sys:ro \
    --volume=/dev:/dev \
    --volume=/var/lib/docker/:/var/lib/docker:ro \
    --volume=/var/lib/kubelet/:/var/lib/kubelet:rw \
    --volume=/var/run:/var/run:rw \
    --net=host \
    --pid=host \
    --privileged=true \
    -d \
    gcr.io/google_containers/hyperkube:v1.0.1 \
    /hyperkube kubelet --containerized --hostname-override=&quot;127.0.0.1&quot; --address=&quot;0.0.0.0&quot; --api-servers=http://localhost:8080 --config=/etc/kubernetes/manifests
```

这一步实际上运行的是 kubelet ，并启动了一个包含其他master组件的[pod](../userguide/pods.md）。

第三步：运行service proxy
```
docker run -d --net=host --privileged gcr.io/google_containers/hyperkube:v1.0.1 /hyperkube proxy --master=http://127.0.0.1:8080 --v=2
```
测试
此时你应该已经运行起了一个Kubernetes集群。你可以下载kubectl二进制程序进行测试：

(OS X) (linux)
注意： 再OS/X上你需要通过ssh设置端口转发：
```
boot2docker ssh -L8080:localhost:8080
```
列出集群中的节点：
```
kubectl get nodes
```
应该输出以下内容：
```
NAME LABELS STATUS
127.0.0.1 Ready
```
如果你运行了不同的Kubernetes集群，你可能需要指定 -s http://localhost:8080 选项来访问本地集群。

运行一个应用
```
kubectl -s http://localhost:8080 run nginx --image=nginx --port=80
```
运行 docker ps 你应该就能看到nginx在运行。下载镜像可能需要等待几分钟。

暴露为service
```
kubectl expose rc nginx --port=80
```
运行以下命令来获取刚才创建的service的IP地址。有两个IP，第一个是内部的

（CLUSTER_IP），第二个是外部的负载均衡IP。
```
kubectl get svc nginx
```
同样你也可以通过运行以下命令只获取第一个IP（CLUSTER_IP）：
```
kubectl get svc nginx --template={{.spec.clusterIP}}
```
通过第一个IP（CLUSTER_IP）访问服务：
```
curl <insert-cluster-ip-here>
```
注意如果再OSX上需要再boot2docker虚拟机上运行curl。

关于关闭集群的说明
上面的各种容器都是运行在 kubelet 程序的管理下，它会保证容器一直运行，甚至容器意外退出时也不例外。所以，如果想关闭集群，你需要首先关闭 kubelet 容器，再关闭其他。

可以使用 docker kill $(docker ps -aq) 。注意这样会关闭Docker下运行的所有容器，请谨慎使用。

